server:
  host: "0.0.0.0"
  port: 8080
  
storage:
  type: "json"
  path: "./data"
  
agents:
  path: "./agents"
  watch: true  # Hot-reload enabled
  
providers:
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    default_model: "claude-sonnet-4-20250514"
  openai:
    api_key: "${OPENAI_API_KEY}"
    default_model: "gpt-4o"
  zai:
    api_key: "${ZAI_API_KEY}"
    base_url: "https://api.z.ai/v1"  # Optional, defaults to this value
    default_model: "glm-4"
  gemini:
    # Choose authentication method:
    # Option 1: Direct API key (set use_cli: false or omit it)
    api_key: "${GEMINI_API_KEY}"
    default_model: "gemini-2.0-flash-exp"
    
    # Option 2: Use Gemini CLI with OAuth (recommended)
    # Requires: npm install -g @google/gemini-cli && gemini (to authenticate)
    # Then start the bridge: cd internal/server/provider/gemini/bridge && npm install && npm start
    use_cli: false                            # Set to true to use CLI
    bridge_url: "http://localhost:3001"       # Node.js bridge URL
  ollama:
    host: "http://localhost:11434"
    default_model: "llama3"

defaults:
  provider: "anthropic"
  temperature: 0.3
  max_tokens: 8192
  
logging:
  level: "info"
  format: "json"
